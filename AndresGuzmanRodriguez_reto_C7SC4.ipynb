{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPF2sJK9mXvxEzOSMuir45C"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Reto: Modelo basado en *deep learning* para la discriminación entre gatos y perros\n",
        "\n",
        "**Objetivos**:\n",
        "- Diseñar modelos de redes neuronales profundas (*deep learning*), enfocándose en la clasificación de imágenes de acuerdo a categrías preestablecidas para resolver problemas con relevancia social, permitiendo valor en los diversos sectores.\n",
        "- Crear modelos de datos *Deep Neural Networks* (DNN) utilizando PyTorch basado en Python; seleccionando el modelo adecuado y analizando la exactitud del modelo, para cumplir lo mejor posible con los requerimientos de la tarea requerida."
      ],
      "metadata": {
        "id": "R2TQDfs6utZk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Preprocesamiento de la base de datos"
      ],
      "metadata": {
        "id": "ML5zsjCG0Bq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GjRN_Rv0EjI",
        "outputId": "f0db3016-835a-41db-c4f1-cbc0119f237e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando bibliotecas\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchsummary import summary\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pathlib"
      ],
      "metadata": {
        "id": "bgksTxl50iav"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminando cualquier archivo que no sea JPG, JPEG, PNG\n",
        "!find /content/drive/MyDrive/Reto_PyTorch/catsvsdogs -type f ! -name '*.jpg' ! -name '*.jpeg' ! -name '.*png' -delete"
      ],
      "metadata": {
        "id": "rYt2NZOs1RRN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Directorio base\n",
        "data_dir = pathlib.Path('/content/drive/MyDrive/Reto_PyTorch/catsvsdogs')\n",
        "conteo_img = len(list(data_dir.glob('*/*')))\n",
        "print('Total de imágenes a analizar:', conteo_img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLFn_Lcf2sAD",
        "outputId": "201c4ee4-c0cb-4dfa-bd29-e5a0af680eb6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de imágenes a analizar: 4895\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformaciones\n",
        "transform = transforms.Compose([\n",
        "    # Ajustar tamaño de la imagen\n",
        "    transforms.Resize((224,224)),\n",
        "    # Transformar a tensor\n",
        "    transforms.ToTensor(),\n",
        "])"
      ],
      "metadata": {
        "id": "xoM2cdXL35rJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 Normalización de las imágenes"
      ],
      "metadata": {
        "id": "odL-EuHA66p_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imagenes sin normalizar\n",
        "dataset = datasets.ImageFolder(data_dir, transform=transform)\n",
        "loader = DataLoader(dataset,batch_size=64,shuffle=False,num_workers=2)\n",
        "\n",
        "# Calculando promedio y desviación estándar\n",
        "mean = 0\n",
        "std = 0\n",
        "total_imgs = 0\n",
        "for images,_ in loader:\n",
        "    batch_samples = images.size(0)\n",
        "    images = images.view(batch_samples,images.size(1),-1) # (batch,canales,pixeles)\n",
        "    mean += images.mean(2).sum(0)\n",
        "    std += images.std(2).sum(0)\n",
        "    total_imgs += batch_samples\n",
        "mean = mean/total_imgs\n",
        "std = std/total_imgs\n",
        "print('Promedio:', mean)\n",
        "print('Desviación estándar:', std)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-XfZ7046_IC",
        "outputId": "85973620-3f69-4cc4-a2f1-70d7c1e33ee4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Promedio: tensor([0.4815, 0.4475, 0.3969])\n",
            "Desviación estándar: tensor([0.2255, 0.2230, 0.2250])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformación final\n",
        "transform = transforms.Compose([\n",
        "    # Ajustar tamaño de la imagen\n",
        "    transforms.Resize((224,224)),\n",
        "    # Transformar a tensor\n",
        "    transforms.ToTensor(),\n",
        "    # Normalizar\n",
        "    transforms.Normalize(mean = [0.4815,0.4475,0.3969],\n",
        "                        std = [0.2255,0.2230,0.2250])\n",
        "])\n"
      ],
      "metadata": {
        "id": "OrDEt6uHAtRP"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Sets de Entrenamiento y Validación"
      ],
      "metadata": {
        "id": "P-B63pwb30G-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset completo desde el directorio establecido\n",
        "dataset = datasets.ImageFolder(data_dir, transform=transform)\n",
        "\n",
        "# División: 80% entrenamiento, 20% validación\n",
        "train_size = int(0.8*len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "train_set, val_set = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "# Batch\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_set,batch_size=batch_size,shuffle=True)\n",
        "val_loader = DataLoader(val_set,batch_size=batch_size,shuffle=False)\n",
        "\n",
        "# Tamaño de los sets\n",
        "print(f'Imágenes:',len(dataset))\n",
        "print(f'Entrenamiento', len(train_set))\n",
        "print(f'Validación', len(val_set))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEysQahz4vf5",
        "outputId": "f2d2caa4-16dc-41ab-efca-5a321bdb8e0e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imágenes: 4895\n",
            "Entrenamiento 3916\n",
            "Validación 979\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Construcción de la Red Neuronal"
      ],
      "metadata": {
        "id": "QfMQAoa5FftT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiLayerPerceptron(nn.Module):\n",
        "    def __init__(self,input_size = 224*224*3,output_size = 2):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_size,512)\n",
        "        self.fc2 = nn.Linear(512,128)\n",
        "        self.fc3 = nn.Linear(128,64)\n",
        "        self.fc4 = nn.Linear(64,output_size)\n",
        "\n",
        "    def forward(self,X):\n",
        "        X = X.view(X.shape[0],-1)\n",
        "        X = F.relu(self.fc1(X))\n",
        "        X = F.relu(self.fc2(X))\n",
        "        X = F.relu(self.fc3(X))\n",
        "        X = self.fc4(X)\n",
        "        return X\n",
        "\n",
        " # Creando el modelo\n",
        "model = MultiLayerPerceptron()\n",
        "\n",
        "# Ver la estructura del modelo\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfXr2ryuF_qZ",
        "outputId": "a1cd5e3c-860b-4596-ae22-8cfc58ef69ea"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MultiLayerPerceptron(\n",
            "  (fc1): Linear(in_features=150528, out_features=512, bias=True)\n",
            "  (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
            "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (fc4): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definiendo pérdida y optimizador\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
        "\n",
        "# Mover a GPU si está disponible\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hd4vC5ZAJWN6",
        "outputId": "1bce2e3b-f71d-4a04-91e6-143e9fce45ee"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultiLayerPerceptron(\n",
              "  (fc1): Linear(in_features=150528, out_features=512, bias=True)\n",
              "  (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
              "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (fc4): Linear(in_features=64, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Entrenamiento de la Red Neuronal"
      ],
      "metadata": {
        "id": "gKJZwusiKNb8"
      }
    }
  ]
}