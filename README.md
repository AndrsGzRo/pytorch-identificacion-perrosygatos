# pytorch-identificacion-perrosygatos

## Introducci√≥n 
Han pasado m√°s de dos a√±os desde que se descubri√≥ la vacuna contra los zombis. Ahora, un nuevo peligro amenaza al mundo: algunas razas de perros son inmunes a la vacuna y pueden crear una nueva cepa del virus.

La empresa estadounidense Small Pet, al darse cuenta del problema, alert√≥ a todos los pa√≠ses. En M√©xico, la empresa Ciencia para el Futuro se ha propuesto apoyar con la creaci√≥n de una aplicaci√≥n para identificar a dichos perros.

Tu misi√≥n: crear una App capaz de identificar r√°pidamente a los perros inmunes, antes de que la nueva cepa del virus mortal afecte a su primera v√≠ctima. ¬øPodr√°s lograrlo antes de que el mundo vuelva a caer en manos de los zombis?

## Objetivos
- Dise√±ar modelos de **redes neuronales profundas (Deep Learning)**, enfocados en la clasificaci√≥n de im√°genes para resolver problemas con relevancia social.

- Crear modelos de **Deep Neural Networks (DNN)** utilizando **PyTorch** y **Python**, seleccionando la arquitectura adecuada y analizando la exactitud del modelo para cumplir con los requerimientos del proyecto.

- Generar valor en diversos sectores mediante la aplicaci√≥n de t√©cnicas de inteligencia artificial a problemas reales.

- Comparar el rendimiento de un perceptr√≥n multicapa (MLP) con una red neuronal convolucional (CNN) en la clasificaci√≥n de im√°genes de perros y gatos.
  
- Guardar y reutilizar modelos entrenados en PyTorch. 

## Tecnolog√≠as y herramientas
- Python
- PyTorch
- Torchvision (para datasets y transformaciones de im√°genes)
- Matplotlib / Seaborn (para visualizaci√≥n de resultados)
- Pathlib (para manejo de rutas de archivos)


## Modelo 1: MultiLayerPerceptron (MLP)
El perceptr√≥n multicapa (MLP) fue el primer modelo implementado para clasificar im√°genes entre perros y gatos, usando √∫nicamente capas totalmente conectadas. 
El MLP no analiza patrones espaciales, sino que trata cada p√≠xel como una entrada independiente, lo que limita su capacidad de generalizaci√≥n en im√°genes, pero es √∫til como punto de partida.

### Arquitectura MLP
| Capa | Tipo | Dimensiones | Funci√≥n |
|------|------|--------------|----------|
| `fc1` | Linear | 150,528 ‚Üí 512 | Capa de entrada, reduce la dimensionalidad del vector de p√≠xeles. |
| `fc2` | Linear | 512 ‚Üí 128 | Extrae patrones combinando activaciones previas. |
| `fc3` | Linear | 128 ‚Üí 64 | Capa intermedia para abstracciones de nivel medio. |
| `fc4` | Linear | 64 ‚Üí 2 | Capa de salida: logits para ‚ÄúCat‚Äù y ‚ÄúDog‚Äù. |

- **Activaci√≥n**: ReLU en capas ocultas.
- **Funci√≥n de p√©rdidas:** CrossEntropyLoss
- **Optimizador**: Adam(lr = 0.001)

### üìä Resultados 
| M√©trica | Entrenamiento | Validaci√≥n |
|----------|----------------|-------------|
| Exactitud | 95.33 % | 61.9 %

El modelo aprende de manera excelente el conjunto de entrenamiento, pero muestra **sobreajuste**, ya que no generaliza bien las im√°genes del conjunto de validaci√≥n.

### ‚ö†Ô∏è Limitaciones 
- No aprovecha la estructura espacial de las im√°genes.
- Requiere demasiados par√°metros.
- Tiende a sobreajustar r√°pidamente datasets peque√±os.

Por estas razones el MLP fue reemplzado por una **Red Convolucional (CNN)**.

## Modelo  2 - Convolutional Neural Network (CNN)

El segundo modelo implementado fue una **Red Neuronal Convolucional (CNN)**, dise√±ada para mejorar la capacidad del sistema al capturar **patrones espaciales** dentro de las im√°genes. A diferencia del MLP, la CNN analiza las im√°genes de forma matricial, aprendiendo autom√°ticamente **bordes, texturas y formas** relevantes para distinguir entre **gatos y perros**. 

###  Arquitectura CNN
| Capa | Tipo | Par√°metros | Tama√±o de salida | Descripci√≥n |
|------|------|-------------|------------------|--------------|
| `conv1` | Conv2d | 3 ‚Üí 32, kernel=3 | 32√ó32√ó32 | Detecta bordes y colores b√°sicos. |
| `pool1` | MaxPool2d | 2√ó2 | 32√ó32√ó32 ‚Üí 32√ó32√ó16 | Reduce la resoluci√≥n, conserva rasgos m√°s relevantes. |
| `conv2` | Conv2d | 32 ‚Üí 64, kernel=3 | 64√ó16√ó16 | Aprende texturas y formas simples. |
| `pool2` | MaxPool2d | 2√ó2 | 64√ó16√ó16 ‚Üí 64√ó16√ó8 | Reduce el tama√±o de representaci√≥n. |
| `conv3` | Conv2d | 64 ‚Üí 128, kernel=3 | 128√ó8√ó8 | Capta caracter√≠sticas complejas y de alto nivel. |
| `pool3` | MaxPool2d | 2√ó2 | 128√ó8√ó8 ‚Üí 128√ó8√ó8 | Consolidaci√≥n final de caracter√≠sticas visuales. |
| `dropout` | Dropout(0.5) | ‚Äî | ‚Äî | Evita sobreajuste desactivando neuronas al azar. |
| `fc1` | Linear | 128√ó8√ó8 ‚Üí 256 | ‚Äî | Combina caracter√≠sticas extra√≠das por las convoluciones. |
| `fc2` | Linear | 256 ‚Üí 2 | ‚Äî | Capa de salida: logits para ‚ÄúCat‚Äù y ‚ÄúDog‚Äù. |

### Detalles del entrenamiento
- **Tama√±o de entrada:** 64x64x3
- **Funci√≥n de p√©rdida:** CrossEntropyLoss.
- **Optimizador:** Adam(lr=0.0005)
- **Regularizaci√≥n:** Dropout(0.5) + BatchNormalization.
- **Epochs:** 25
- **Scheduler:** Reduce learning rate cada 7 epochs. 
###  üìà Resultados CNN
| M√©trica | Entrenamiento | Validaci√≥n |
|----------|----------------|-------------|
| Exactitud | **81.4 %** | **76.4 %** |
| P√©rdida | 0.40 | 0.48 |

La CNN muestra una clara mejora en precisi√≥n y estabilidad respecto al MLP, reduciendo el sobreajuste y generalizando mejor en datos no vistos. 

### Ventajas del modelo
- Aprende **caracter√≠sticas visuales jer√°rquicas**.
- Requiere **menos par√°metros** que el MLP para lograr mayor rendimiento.
- Es m√°s **robusta a traslaciones y variaciones** en las im√°genes.
- Puede escalarse f√°cilmente usando arquitecturas preentrenadas.

## ‚öñÔ∏è Comparativa entre MLP y CNN

| Caracter√≠stica | MLP | CNN |
|----------------|-----|-----|
| **Tipo de entrada** | Imagen aplanada (1D) | Imagen 2D (mantiene estructura espacial) |
| **Capas principales** | Lineales (Fully Connected) | Convolucionales + Pooling |
| **Capacidad para detectar patrones visuales** | ‚ùå Muy limitada | ‚úÖ Alta (bordes, texturas, formas) |
| **N√∫mero de par√°metros** | Muy alto (millones) | Mucho menor |
| **Riesgo de sobreajuste** | Alto | Moderado |
| **Exactitud en validaci√≥n** | ~60 % | **~76 %** |
| **Generalizaci√≥n** | Pobre | Buena |
| **Eficiencia computacional** | Baja | Alta |
| **Uso recomendado** | Pruebas iniciales o datasets tabulares | Clasificaci√≥n de im√°genes y visi√≥n artificial |

## Conclusi√≥n 
> La CNN logra un equilibrio √≥ptimo entre precisi√≥n y capacidad de generalizaci√≥n.
> Representa una mejora significativa sobre el MLP al aprovechar la estructura espacial de las im√°genes, reduciendo par√°metros y sobreajuste.


